{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c10f0b",
   "metadata": {},
   "source": [
    "\n",
    "# House Prices â€” Minimal XGBoost Pipeline (No folders, minimal I/O)\n",
    "\n",
    "This notebook is **Kaggle-friendly**:\n",
    "- No directory creation, no intermediate files.\n",
    "- In-memory cleaning (no one-hot), training, validation, and final prediction.\n",
    "- Writes a single `submission.csv` in the current working directory.\n",
    "\n",
    "It uses:\n",
    "- A lightweight cleaner that keeps categorical columns as `category` (for `XGBRegressor(enable_categorical=True)`).\n",
    "- Simple feature engineering (`TotalSF`, `AgeSinceBuilt`, `AgeSinceRemod`), optional cap on `GrLivArea`.\n",
    "- Rare-category grouping (maps infrequent levels to `'Other'`).\n",
    "\n",
    "> Paths default to Kaggle competition dataset: `/kaggle/input/house-prices-advanced-regression-techniques/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d47a4b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:28:35.631933Z",
     "start_time": "2025-10-04T17:28:35.422837Z"
    }
   },
   "source": [
    "\n",
    "import os, sys, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_DIR = \"../data\"\n",
    "TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_CSV  = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "LOG_TARGET = False  # True if you want to train on log1p(y) and inverse-transform when evaluating/predicting\n",
    "CAP_GRLIVAREA = 4000.0  # set to None to disable\n",
    "RARE_THRESH = 0.02      # combine categories occurring < 2% into 'Other'\n",
    "\n",
    "# XGB params (sensible defaults for this dataset)\n",
    "XGB_PARAMS = dict(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "140f94db",
   "metadata": {},
   "source": [
    "## Cleaner (no one-hot, keep categorical dtype)"
   ]
  },
  {
   "cell_type": "code",
   "id": "25c117f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:28:36.812319Z",
     "start_time": "2025-10-04T17:28:36.782442Z"
    }
   },
   "source": [
    "\n",
    "MISSING_MEANS_NONE = {\n",
    "    \"PoolQC\": \"NoPool\",\n",
    "    \"Alley\": \"NoAlley\",\n",
    "    \"Fence\": \"NoFence\",\n",
    "    \"FireplaceQu\": \"NoFireplace\",\n",
    "    \"GarageType\": \"NoGarage\",\n",
    "    \"GarageFinish\": \"NoGarage\",\n",
    "    \"GarageQual\": \"NoGarage\",\n",
    "    \"GarageCond\": \"NoGarage\",\n",
    "    \"BsmtQual\": \"NoBasement\",\n",
    "    \"BsmtCond\": \"NoBasement\",\n",
    "    \"BsmtExposure\": \"NoBasement\",\n",
    "    \"BsmtFinType1\": \"NoBasement\",\n",
    "    \"BsmtFinType2\": \"NoBasement\",\n",
    "    \"MiscFeature\": \"None\",\n",
    "    \"MasVnrType\": \"None\",\n",
    "}\n",
    "\n",
    "class RareCategoryGrouper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rare_thresh: float = 0.02):\n",
    "        self.rare_thresh = rare_thresh\n",
    "        self.frequent_levels_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        Xs = X.copy()\n",
    "        self.frequent_levels_.clear()\n",
    "        for col in Xs.columns:\n",
    "            vc = Xs[col].astype(\"string\").fillna(pd.NA).value_counts(normalize=True, dropna=True)\n",
    "            self.frequent_levels_[col] = set(vc[vc >= self.rare_thresh].index.tolist())\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xs = X.copy()\n",
    "        for col in Xs.columns:\n",
    "            good = self.frequent_levels_.get(col, set())\n",
    "            mask = Xs[col].notna()\n",
    "            Xs.loc[mask, col] = Xs.loc[mask, col].astype(\"string\").where(\n",
    "                Xs.loc[mask, col].astype(\"string\").isin(good), other=\"Other\"\n",
    "            )\n",
    "        return Xs\n",
    "\n",
    "class SpecialRulesAndFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cap_grlivarea=4000.0, create_features=True):\n",
    "        self.cap = cap_grlivarea\n",
    "        self.create_features = create_features\n",
    "        self.group_median_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if {\"LotFrontage\",\"Neighborhood\"}.issubset(X.columns):\n",
    "            self.group_median_ = X.groupby(\"Neighborhood\")[\"LotFrontage\"].median()\n",
    "        else:\n",
    "            self.group_median_ = None\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xw = X.copy()\n",
    "\n",
    "        # MSSubClass -> string (categorical later)\n",
    "        if \"MSSubClass\" in Xw.columns:\n",
    "            Xw[\"MSSubClass\"] = Xw[\"MSSubClass\"].astype(\"Int64\").astype(\"string\")\n",
    "\n",
    "        # No garage -> GarageYrBlt = 0\n",
    "        if \"GarageType\" in Xw.columns and \"GarageYrBlt\" in Xw.columns:\n",
    "            no_garage = Xw[\"GarageType\"].isna() | (Xw[\"GarageType\"].astype(\"string\").str.lower().isin([\"nan\",\"none\"]))\n",
    "            Xw.loc[no_garage, \"GarageYrBlt\"] = Xw.loc[no_garage, \"GarageYrBlt\"].fillna(0)\n",
    "\n",
    "        # LotFrontage by Neighborhood median (others remain NaN)\n",
    "        if self.group_median_ is not None and \"LotFrontage\" in Xw.columns and \"Neighborhood\" in Xw.columns:\n",
    "            need = Xw[\"LotFrontage\"].isna()\n",
    "            Xw.loc[need, \"LotFrontage\"] = Xw.loc[need, \"Neighborhood\"].map(self.group_median_)\n",
    "\n",
    "        # Cap GrLivArea\n",
    "        if self.cap is not None and \"GrLivArea\" in Xw.columns:\n",
    "            Xw[\"GrLivArea\"] = np.where(\n",
    "                Xw[\"GrLivArea\"].notna(), np.minimum(Xw[\"GrLivArea\"], self.cap), Xw[\"GrLivArea\"]\n",
    "            )\n",
    "\n",
    "        # Simple features\n",
    "        if self.create_features:\n",
    "            for req in [\"1stFlrSF\",\"2ndFlrSF\",\"TotalBsmtSF\"]:\n",
    "                if req not in Xw.columns: Xw[req] = np.nan\n",
    "            Xw[\"TotalSF\"] = Xw[\"1stFlrSF\"] + Xw[\"2ndFlrSF\"] + Xw[\"TotalBsmtSF\"]\n",
    "\n",
    "            for req in [\"YrSold\",\"YearBuilt\",\"YearRemodAdd\"]:\n",
    "                if req not in Xw.columns: Xw[req] = np.nan\n",
    "            Xw[\"AgeSinceBuilt\"] = Xw[\"YrSold\"] - Xw[\"YearBuilt\"]\n",
    "            Xw[\"AgeSinceRemod\"] = Xw[\"YrSold\"] - Xw[\"YearRemodAdd\"]\n",
    "\n",
    "        return Xw\n",
    "\n",
    "class XGBCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rare_thresh=0.02, cap_grlivarea=4000.0, create_features=True, impute_numeric=False):\n",
    "        self.rare_thresh = rare_thresh\n",
    "        self.cap = cap_grlivarea\n",
    "        self.create_features = create_features\n",
    "        self.impute_numeric = impute_numeric\n",
    "\n",
    "        self.special_ = SpecialRulesAndFeatures(cap_grlivarea=self.cap, create_features=self.create_features)\n",
    "        self.rare_ = RareCategoryGrouper(rare_thresh=self.rare_thresh)\n",
    "\n",
    "        self.cat_cols_ = []\n",
    "        self.num_cols_ = []\n",
    "        self.cat_levels_ = {}\n",
    "\n",
    "    def _detect_cols(self, X):\n",
    "        all_features = [c for c in X.columns if c.lower() != \"id\"]\n",
    "        likely_cat = [\n",
    "            \"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\",\"LandContour\",\"Utilities\",\"LotConfig\",\"LandSlope\",\n",
    "            \"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\"RoofStyle\",\"RoofMatl\",\n",
    "            \"Exterior1st\",\"Exterior2nd\",\"ExterQual\",\"ExterCond\",\"Foundation\",\"Heating\",\"HeatingQC\",\n",
    "            \"CentralAir\",\"Electrical\",\"KitchenQual\",\"Functional\",\"PavedDrive\",\"SaleType\",\"SaleCondition\"\n",
    "        ]\n",
    "        obj_cols = X[all_features].select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "        cat = list(dict.fromkeys([c for c in likely_cat if c in all_features] + obj_cols))\n",
    "        cat_none_cols = [c for c in MISSING_MEANS_NONE.keys() if c in all_features]\n",
    "        cat = list(dict.fromkeys(cat + cat_none_cols))\n",
    "        num = [c for c in X[all_features].select_dtypes(include=[\"number\"]).columns if c not in cat]\n",
    "        self.cat_cols_, self.num_cols_ = cat, num\n",
    "        return all_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        Xw = self.special_.fit_transform(X)\n",
    "        for c, lvl in MISSING_MEANS_NONE.items():\n",
    "            if c in Xw.columns:\n",
    "                Xw[c] = Xw[c].astype(\"string\")\n",
    "                Xw[c] = Xw[c].fillna(lvl).replace({\"nan\": lvl, \"None\": lvl})\n",
    "        self._detect_cols(Xw)\n",
    "\n",
    "        cat_df = Xw[self.cat_cols_].copy()\n",
    "        self.rare_.fit(cat_df)\n",
    "\n",
    "        cat_df = self.rare_.transform(cat_df)\n",
    "        self.cat_levels_.clear()\n",
    "        for c in cat_df.columns:\n",
    "            levels = pd.Series(cat_df[c].dropna().astype(\"string\").unique()).tolist()\n",
    "            if \"Other\" not in levels: levels.append(\"Other\")\n",
    "            self.cat_levels_[c] = sorted([str(v) for v in levels])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xw = self.special_.transform(X)\n",
    "        for c, lvl in MISSING_MEANS_NONE.items():\n",
    "            if c in Xw.columns:\n",
    "                Xw[c] = Xw[c].astype(\"string\")\n",
    "                Xw[c] = Xw[c].fillna(lvl).replace({\"nan\": lvl, \"None\": lvl})\n",
    "        self._detect_cols(Xw)\n",
    "\n",
    "        cat_df = Xw[self.cat_cols_].copy()\n",
    "        for c in cat_df.columns:\n",
    "            mask = cat_df[c].notna()\n",
    "            good = self.rare_.frequent_levels_.get(c, set())\n",
    "            cat_df.loc[mask, c] = cat_df.loc[mask, c].astype(\"string\").where(\n",
    "                cat_df.loc[mask, c].astype(\"string\").isin(good), other=\"Other\"\n",
    "            )\n",
    "        for c in cat_df.columns:\n",
    "            levels = self.cat_levels_.get(c, [\"Other\"])\n",
    "            s = cat_df[c].astype(\"string\")\n",
    "            s = s.where(s.isin(levels), other=\"Other\")\n",
    "            cat_df[c] = pd.Categorical(s, categories=levels)\n",
    "\n",
    "        num_df = Xw[self.num_cols_].copy()\n",
    "        if self.impute_numeric:\n",
    "            for c in num_df.columns:\n",
    "                if num_df[c].isna().any():\n",
    "                    num_df[c] = num_df[c].fillna(num_df[c].median())\n",
    "\n",
    "        return pd.concat([num_df, cat_df], axis=1)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c56c436d",
   "metadata": {},
   "source": [
    "## Load train/test, clean, and split"
   ]
  },
  {
   "cell_type": "code",
   "id": "be2fdcd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:28:40.018473Z",
     "start_time": "2025-10-04T17:28:39.765988Z"
    }
   },
   "source": [
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "TARGET = \"SalePrice\"\n",
    "y = train_df[TARGET].values\n",
    "X_raw = train_df.drop(columns=[TARGET], errors=\"ignore\")\n",
    "\n",
    "cleaner = XGBCleaner(\n",
    "    rare_thresh=RARE_THRESH,\n",
    "    cap_grlivarea=CAP_GRLIVAREA,\n",
    "    create_features=True,\n",
    "    impute_numeric=False  # XGB can handle NaNs\n",
    ")\n",
    "cleaner.fit(X_raw, y)\n",
    "X_clean = cleaner.transform(X_raw)\n",
    "X_submit = cleaner.transform(test_df)\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_clean, y, test_size=TEST_SIZE, random_state=SEED)\n",
    "\n",
    "X_clean.shape, X_submit.shape, X_tr.shape, X_va.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 82), (1459, 82), (1168, 82), (292, 82))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "21c0d4f0",
   "metadata": {},
   "source": [
    "## Train & validate XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2bcfd32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:28:46.620874Z",
     "start_time": "2025-10-04T17:28:43.238765Z"
    }
   },
   "source": [
    "\n",
    "y_tr_fit = np.log1p(y_tr) if LOG_TARGET else y_tr\n",
    "\n",
    "model = XGBRegressor(**XGB_PARAMS)\n",
    "model.fit(X_tr, y_tr_fit)\n",
    "\n",
    "pred_log = model.predict(X_va)\n",
    "pred = np.expm1(pred_log) if LOG_TARGET else pred_log\n",
    "\n",
    "metrics = {\n",
    "    \"rmse\": rmse(y_va, pred),\n",
    "    \"r2\": float(r2_score(y_va, pred)),\n",
    "    \"log_target\": bool(LOG_TARGET)\n",
    "}\n",
    "metrics\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 25522.873819380136, 'r2': 0.9150730967521667, 'log_target': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d63750ed",
   "metadata": {},
   "source": [
    "## Train on full data & create submission"
   ]
  },
  {
   "cell_type": "code",
   "id": "acf60b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:28:55.542881Z",
     "start_time": "2025-10-04T17:28:51.641922Z"
    }
   },
   "source": [
    "\n",
    "y_fit_full = np.log1p(y) if LOG_TARGET else y\n",
    "final_model = XGBRegressor(**XGB_PARAMS)\n",
    "final_model.fit(X_clean, y_fit_full)\n",
    "\n",
    "test_pred_log = final_model.predict(X_submit)\n",
    "test_pred = np.expm1(test_pred_log) if LOG_TARGET else test_pred_log\n",
    "\n",
    "submission = pd.DataFrame({\"Id\": test_df[\"Id\"], \"SalePrice\": test_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"[OK] Saved submission.csv\")\n",
    "submission.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  122834.570312\n",
       "1  1462  166305.734375\n",
       "2  1463  183328.203125\n",
       "3  1464  193722.140625\n",
       "4  1465  184686.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122834.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>166305.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>183328.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>193722.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>184686.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab6a67692ad01c9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
